## OpenShift Container Storage Concepts
In this lab we are going to provide a view 'under the hood' of OpenShift
`PersistentVolumes` provided by OpenShift Container Storage (OCS). For this
purpose we will examine volumes leveraged by example applications using
different volume access modes.

### How OpenShift Container Storage runs

Make sure you are logged on as the super user in the `{{CNS_NAMESPACE}}`:

[source,bash,role="copypaste"]
----
oc login -u system:admin -n {{CNS_NAMESPACE}}
----

OpenShift Container Storage is GlusterFS running in containers, specifically
in pods managed by OpenShift. We have looked at the pods making up the
storage cluster already in the introduction chapter. Go ahead and switch to the
storage project:

[source,bash,role="copypaste"]
----
oc project -n {{ CNS_NAMESPACE }}
----

Then, take a look at the storage *Pods*:

[source,bash,role="copypaste"]
----
oc get pods -o wide
----

Which yields:

----
NAME                      READY     STATUS    RESTARTS   AGE       IP           NODE                                          NOMINATED NODE
glusterfs-storage-7qzsm   1/1       Running   0          2h        10.0.3.252   {{NODE1_INTERNAL_FQDN}} <1>   <none>
glusterfs-storage-7rds5   1/1       Running   0          2h        10.0.1.238   {{NODE2_INTERNAL_FQDN}} <1>   <none>
glusterfs-storage-x7chr   1/1       Running   0          2h        10.0.4.221   {{NODE3_INTERNAL_FQDN}} <1>   <none>
heketi-storage-1-bxqr2    1/1       Running   0          2h        10.131.0.6   {{INFRA_INTERNAL_FQDN}} <2>   <none>
----
<1> OCS *Pods*, with each of the designated nodes running exactly one.
<2> heketi API frontend pod

[NOTE]
====
The exact *pod* names will be different in your environment, since they are
auto-generated. Also the heketi *pod* might run on any node.
====

The OCS *Pods* use the host's network and block devices to run the
software-defined storage system. See schematic below for a visualization.

.GlusterFS pods in OCS in detail.
image::cns_diagram_pod.png[]

`heketi` is a component that exposes an API to the storage system for
OpenShift. This allows OpenShift to dynamically allocate storage from OCS in a
programmatic fashion. See below for a visualization. Note that for simplicity,
in our example heketi runs on the OpenShift application nodes, not on the
infrastructure node.

.heketi pod running in OCS
image::cns_diagram_heketi.png[]

#### Examine heketi
To expose heketi's API outside of OpenShift for administrators (for
monitoring and maintenance), a *Service* named _heketi-storage_ and a *Route*
has been set up:

[source,bash,role="copypaste"]
----
oc get service,route
----

You will see something like:

----
NAME                              TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
svc/heketi-db-storage-endpoints   ClusterIP   172.30.228.77   <none>        1/TCP      2h
svc/heketi-storage                ClusterIP   172.30.54.191   <none>        8080/TCP   2h

NAME                                      HOST/PORT                                                              PATH      SERVICES         PORT      TERMINATION   WILDCARD
route.route.openshift.io/heketi-storage   heketi-storage-{{CNS_NAMESPACE}}.{{OCP_ROUTING_SUFFIX}}             heketi-storage   <all>                   None
----

You may verify external availability of this API and heketi being alive with a trivial health check:

[source,bash,role="copypaste"]
----
curl -w "\n" http://heketi-storage-{{CNS_NAMESPACE}}.{{OCP_ROUTING_SUFFIX}}/hello
----

This should return:

----
Hello from Heketi
----

This how the heketi API is made available to both external clients, like
`heketi-cli` which we examined in the introduction. But mainly it is
leveraged by OpenShift to provision storage dynamically. Let's look at this
use case.

### A Simple OCS Use Case

We are going to deploy a sample application that ships with OpenShift which
creates a PVC as part of the deployment. Log on to the system as
`fancyuser1`, using the password `openshift` and create a project with the
name `my-database-app`.

#### Create/Deploy the Application

[source,bash,role="copypaste"]
----
oc login -u fancyuser1 -p openshift
oc new-project my-database-app
----

The example application ships in the form of ready-to-use resource templates. Enter
the following command to look at the template for a sample Ruby on Rails
application with a PostgreSQL database:

[source,bash,role="copypaste"]
----
oc get template/rails-pgsql-persistent -n openshift
----

This template creates a Rails Application instance which mimics a very basic
weblog. The articles and comments are saved in a PostgreSQL database which runs
in another pod.

As part of the resource template, a PVC is created in the YAML. Run the following command to `grep` the relavant part:


[source,bash,role="copypaste"]
----
oc get template/rails-pgsql-persistent -n openshift -o yaml | grep PersistentVolumeClaim -A8
----

This shows the basic structure of a `PersistentVolumeClaim`:

[source,yaml]
----
kind: PersistentVolumeClaim
metadata:
  name: ${DATABASE_SERVICE_NAME}
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: ${VOLUME_CAPACITY}
----

This will request a *PersistentVolume* in `RWO` mode. Storage provided in
this mode can only be mounted by a single pod at a time. For a database that
is usually what you want. The requested capacity under
`spec.resources.requests.storage` is coming in via a parameter when the
template is parsed. This is how storage is _requested_.

Using persistent storage is done via a `PersistentVolume` provided in
response to this `PersistentVolumeClaim`. A `PersistentVolume` is a
representation of some physical storage capacity provisioned by the backing
storage system. It will supply the PostgreSQL pod with persistent storage on
the mount point `/var/lib/pgsql/data`.

You can see this when inspecting how the pod is described as part of the
`DeploymentConfig`:

[source,bash,role="copypaste"]
----
oc get template/rails-pgsql-persistent -n openshift -o yaml | grep mountPath -B58 -A5
----

Will show:

[source,yaml]
----
- apiVersion: v1
  kind: DeploymentConfig
  metadata:
    annotations:
      description: Defines how to deploy the database
      template.alpha.openshift.io/wait-for-ready: "true"
    name: ${DATABASE_SERVICE_NAME}
  spec:
    replicas: 1
    selector:
      name: ${DATABASE_SERVICE_NAME}
    strategy:
      type: Recreate
    template:
      metadata:
        labels:
          name: ${DATABASE_SERVICE_NAME}
        name: ${DATABASE_SERVICE_NAME}
      spec:
        containers:
        - env:
          - name: POSTGRESQL_USER
            valueFrom:
              secretKeyRef:
                key: database-user
                name: ${NAME}
          - name: POSTGRESQL_PASSWORD
            valueFrom:
              secretKeyRef:
                key: database-password
                name: ${NAME}
          - name: POSTGRESQL_DATABASE
            value: ${DATABASE_NAME}
          - name: POSTGRESQL_MAX_CONNECTIONS
            value: ${POSTGRESQL_MAX_CONNECTIONS}
          - name: POSTGRESQL_SHARED_BUFFERS
            value: ${POSTGRESQL_SHARED_BUFFERS}
          image: ' '
          livenessProbe:
            initialDelaySeconds: 30
            tcpSocket:
              port: 5432
            timeoutSeconds: 1
          name: postgresql
          ports:
          - containerPort: 5432
          readinessProbe:
            exec:
              command:
              - /bin/sh
              - -i
              - -c
              - psql -h 127.0.0.1 -U ${POSTGRESQL_USER} -q -d ${POSTGRESQL_DATABASE}
                -c 'SELECT 1'
            initialDelaySeconds: 5
            timeoutSeconds: 1
          resources:
            limits:
              memory: ${MEMORY_POSTGRESQL_LIMIT}
          volumeMounts:
          - mountPath: /var/lib/pgsql/data <1>
            name: ${DATABASE_SERVICE_NAME}-data <2>
        volumes:
        - name: ${DATABASE_SERVICE_NAME}-data <2>
          persistentVolumeClaim:
            claimName: ${DATABASE_SERVICE_NAME} <3>
----
<1> The mount path where the persistent storage should appear inside the container
<2> The name of the volume known by the container
<3> The `PersistentVolumeClaim` from which this volume should come from

[TIP]
====
In the above snippet you see there are even more parameters in this template.
If you want to see more about the parameters or other details of this
template, you can execute the following:

 oc describe template rails-pgsql-persistent -n openshift
====

The following diagram sums up how storage get's provisioned in OpenShift and
depicts the relationship of `PersistentVolumes`, `PersistentVolumeClaims` and
`StorageClasses`:

.OpenShift Persistent Volume Framework
image::cns_diagram_pvc.png[]

Let's try it out. The storage size parameter in the template is called
`VOLUME_CAPACITY`. The `new-app` command will again handle processing and
interpreting a *Template* into the appropriate OpenShift objects. We will
specify that we want _5Gi_ of storage as part of deploying a new app from the
template as follows:

[source,bash,role="copypaste"]
----
oc new-app rails-pgsql-persistent -p VOLUME_CAPACITY=5Gi
----

[NOTE]
====
The `new-app` command will automatically check for templates in the special
`openshift` namespace. In fact, `new-app` tries to do quite a lot of interesting
automagic things, including code introspection when pointed at code
repositories. It is a developer's good friend.
====

You will then see something like the following:

----
--> Deploying template "openshift/rails-pgsql-persistent" to project my-database-app                                                                                                                       [2/1622]

     Rails + PostgreSQL
     ---------
     An example Rails application with a PostgreSQL database. For more information about using this template, including OpenShift considerations, see https://github.com/openshift/rails-ex/blob/master/README.md.

     The following service(s) have been created in your project: rails-pgsql-persistent, postgresql.
     
     For more information about using this template, including OpenShift considerations, see https://github.com/openshift/rails-ex/blob/master/README.md.

     * With parameters:
        * Name=rails-pgsql-persistent
        * Namespace=openshift
        * Memory Limit=512Mi
        * Memory Limit (PostgreSQL)=512Mi
        * Volume Capacity=5Gi
        * Git Repository URL=https://github.com/openshift/rails-ex.git
        * Git Reference=
        * Context Directory=
        * Application Hostname=
        * GitHub Webhook Secret=pIXDthfeGR7PHxxbASEjCM7jQ0hAJ8Ph8HTIttvl # generated
        * Secret Key=ij54gqv7w04habvy6dn2sninbbdgmlicwnsvpfwa1gdn6of2rrxgo211njqaekqlhg1503xdnvo2oc7h3dk7dd3cmk7h8mvnmijikovjw5jnl2w2pnfrukkwx0sq0uj # generated
        * Application Username=openshift
        * Application Password=secret
        * Rails Environment=production
        * Database Service Name=postgresql
        * Database Username=userAFJ # generated
        * Database Password=pn6A2x3B # generated
        * Database Name=root
        * Maximum Database Connections=100
        * Shared Buffer Amount=12MB
        * Custom RubyGems Mirror URL=

--> Creating resources ...
    secret "rails-pgsql-persistent" created
    service "rails-pgsql-persistent" created
    route.route.openshift.io "rails-pgsql-persistent" created
    imagestream.image.openshift.io "rails-pgsql-persistent" created
    buildconfig.build.openshift.io "rails-pgsql-persistent" created
    deploymentconfig.apps.openshift.io "rails-pgsql-persistent" created
    persistentvolumeclaim "postgresql" created
    service "postgresql" created
    deploymentconfig.apps.openshift.io "postgresql" created
--> Success
    Access your application via route 'rails-pgsql-persistent-my-database-app.apps.790442527540.aws.testdrive.openshift.com' 
    Build scheduled, use 'oc logs -f bc/rails-pgsql-persistent' to track its progress.
    Run 'oc status' to view your app.
----

Go back to the OpenShift web console:

*{{WEB_CONSOLE_URL}}*

Make sure you are logged in as _fancyuser1_ and find your newly created
project `my-database-app`. You can now follow the deployment process here.
The deployment is complete when both the PostgreSQL pod and the Ruby
application pod have one healthy instance (rings are dark, solid blue).

[NOTE]
====
It may take up to 5 minutes for the deployment to complete.
====

On the CLI, you should now see a PVC that has been issued and has a status of _Bound_.
state.

[source,bash,role="copypaste"]
----
oc get pvc
----

You will see something like:

----
NAME         STATUS    VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS        AGE
postgresql   Bound     pvc-6de8449e-3f34-11e8-87ea-0298f449cc4c   5Gi        RWO            {{ CNS_STORAGECLASS }}   4m
----

Alternatively, in the web console, check the *"Storage"* menu.

[TIP]
====
This PVC has been automatically fulfilled by OCS because the `{{
CNS_STORAGECLASS }}` *StorageClass* was set up as the system-wide default as
part of the installation. The responsible parameter in the inventory file
was: `openshift_storage_glusterfs_storageclass_default=true`
====

#### Try the Application
Now go ahead and try out the application. The overview page in the OpenShift
web console will tell you the *Route* which has been deployed as well.
Otherwise get it on the CLI like this:

[source,bash,role="copypaste"]
----
oc get route
----

You will see something like:

----
NAME                     HOST/PORT                                                      PATH      SERVICES                 PORT      TERMINATION   WILDCARD
rails-pgsql-persistent   rails-pgsql-persistent-my-database-app.{{OCP_ROUTING_SUFFIX}}            rails-pgsql-persistent   <all>                   None
----

Following this output, point your browser to:

*http://rails-pgsql-persistent-my-database-app.{{OCP_ROUTING_SUFFIX}}/articles*

The username/password to create articles and comments is by default
'_openshift_'/'_secret_'.

You should be able to successfully create articles and comments. When they are
saved they are actually saved in the PostgreSQL database which stores its table
spaces on a GlusterFS volume provided by OCS.

[NOTE]
====
This application's template included a *Route* object definition, which is
why the *Service* was automatically exposed. This is a good practice. Note
how the actual application is hosted under the */articles* path of the URL.
====

#### Explore the underlying OCS artifacts
Now let's take a look at how this was deployed on the GlusterFS side. First you
need to acquire necessary permissions:

[source,bash,role="copypaste"]
----
oc login -u system:admin
----

Select the example project of the user `fancyuser1` if not already/still selected:

[source,bash,role="copypaste"]
----
oc project my-database-app
----

Look at the PVC to determine the PV:

[source,bash,role="copypaste"]
----
oc get pvc
----

You will see the PVC in a `BOUND` state and the name of the PV it has been bound to in the `VOLUME` column:

----
NAME         STATUS    VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS        AGE
postgresql   Bound     pvc-6de8449e-3f34-11e8-87ea-0298f449cc4c   5Gi        RWO            glusterfs-storage   144m
----

[NOTE]
====
Your PV name will be different as it's dynamically generated. A lot of the
following things contain dynamically generated names.
*Use the supplied bash shortcuts to easy copying and pasting.*
====

Here's a little bash shortcut to store the name of the PVC in a Bash environment variable:

[source,bash,role="copypaste"]
----
export PGSQL_PV_NAME=$(oc get pvc/postgresql -o jsonpath="{.spec.volumeName}" -n my-database-app)
echo $PGSQL_PV_NAME
----

Look at the details of the PV bound to the PVC, in this case
`pvc-6de8449e-3f34-11e8-87ea-0298f449cc4c` (your's will be different, use the bash variable):

[source,bash,role="copypaste"]
----
oc describe pv $PGSQL_PV_NAME
----

You will see something like:

----
Name:		         pvc-6de8449e-3f34-11e8-87ea-0298f449cc4c <1>
Labels:          <none>
Annotations:     Description=Gluster-Internal: Dynamically provisioned PV
                 gluster.kubernetes.io/heketi-volume-id=7da624d82941c50d704dd01b366c5806
                 gluster.org/type=file
                 kubernetes.io/createdby=heketi-dynamic-provisioner
                 pv.beta.kubernetes.io/gid=2001
                 pv.kubernetes.io/bound-by-controller=yes
                 pv.kubernetes.io/provisioned-by=kubernetes.io/glusterfs
                 volume.beta.kubernetes.io/mount-options=auto_unmount
Finalizers:      [kubernetes.io/pv-protection]
StorageClass:	   {{ CNS_STORAGECLASS }}
Status:          Bound
Claim:           my-database-app/postgresql
Reclaim Policy:  Delete
Access Modes:    RWO
Capacity:        5Gi
Node Affinity:   <none>
Message:         
Source:
    Type:           Glusterfs (a Glusterfs mount on the host that shares a pod's lifetime)
    EndpointsName:  glusterfs-dynamic-postgresql
    Path:		        vol_e8fe7f46fedf7af7628feda0dcbf2f60 <2>
    ReadOnly:       false
Events:             <none>
----
<1> The unique name of this PV in the system OpenShift refers to
<2> The unique volume name backing the PV known to GlusterFS

Note the GlusterFS volume name, in this case
*vol_e8fe7f46fedf7af7628feda0dcbf2f60*. The following is another Bash
shortcut to store the name of the GlusterFS volume backing the
`PersistentVolume`:

[source,bash,role="copypaste"]
----
export PGSQL_GLUSTER_VOLUME=$(oc get pv $PGSQL_PV_NAME -o jsonpath='{.spec.glusterfs.path}')
echo $PGSQL_GLUSTER_VOLUME
----

Now let's switch to the namespace we used for OCS deployment:

[source,bash,role="copypaste"]
----
oc project {{ CNS_NAMESPACE }}
----

Look at the GlusterFS pods running and pick one (which one is not important):

[source,bash,role="copypaste"]
----
oc get pods -o wide -l glusterfs=storage-pod
----

You will see something like:

----
NAME                      READY     STATUS    RESTARTS   AGE       IP           NODE                                          NOMINATED NODE
glusterfs-storage-7qzsm   1/1       Running   0          2h        10.0.3.252   {{NODE1_INTERNAL_FQDN}}   <none>
glusterfs-storage-7rds5   1/1       Running   0          2h        10.0.1.238   {{NODE2_INTERNAL_FQDN}}   <none>
glusterfs-storage-x7chr   1/1       Running   0          2h        10.0.4.221   {{NODE3_INTERNAL_FQDN}}   <none>
----

We are now going to select the first pod (which one doesn't really matter)
and, store it's IP address in above example that is: *{{NODE1_INTERNAL_IP}}*
of pod *glusterfs-storage-37vn8*.

Again, for easy copying and pasting, here are some Bash shortcuts:

[source,bash,role="copypaste"]
----
export FIRST_GLUSTER_POD=$(oc get pods -o jsonpath='{.items[0].metadata.name}' -l glusterfs=storage-pod)
export FIRST_GLUSTER_IP=$(oc get pods -o jsonpath='{.items[0].status.podIP}' -l glusterfs=storage-pod)
echo $FIRST_GLUSTER_POD
echo $FIRST_GLUSTER_IP
----

We will again use the `oc rsh` facility to log on to the selected GlusterFS
pod which has the GlusterFS CLI utilities installed. This time we will use
the non-interactive mode which immediately drops out after executing the
supplied command.

Query GlusterFS from inside the first GlusterFS pod for all known volumes:

[source,bash,role="copypaste"]
----
oc rsh $FIRST_GLUSTER_POD gluster volume list
----

You will immediately drop back out to your shell and you will see something like:

----
heketidbstorage <1>
vol_e8fe7f46fedf7af7628feda0dcbf2f60 <2>
vol_5e1cd71070734a3b02f58d822f89486a
vol_f2e8fda1d42a41efabbb4d4a3b4a5659
----
<1> A special volume dedicated to heketi's internal database.
<2> The volume backing the PV of the PostgreSQL database we asked you to remember.

Query GlusterFS about the topology of this volume:

[source,bash,role="copypaste"]
----
oc rsh $FIRST_GLUSTER_POD gluster volume info $PGSQL_GLUSTER_VOLUME
----

You will see something like:

----
Volume Name: vol_e8fe7f46fedf7af7628feda0dcbf2f60
Type: Replicate
Volume ID: c2bedd16-8b0d-432c-b9eb-4ab1274826dd
Status: Started
Snapshot Count: 0
Number of Bricks: 1 x 3 = 3
Transport-type: tcp
Bricks:
Brick1: {{NODE2_INTERNAL_IP}}:/var/lib/heketi/mounts/vg_63b05bee6695ee5a63ad95bfbce43bf7/brick_aa28de668c8c21192df55956a822bd3c/brick
Brick2: {{NODE1_INTERNAL_IP}}:/var/lib/heketi/mounts/vg_0246fd563709384a3cbc3f3bbeeb87a9/brick_684a01f8993f241a92db02b117e0b912/brick <1>
Brick3: {{NODE3_INTERNAL_IP}}:/var/lib/heketi/mounts/vg_5a8c767e65feef7455b58d01c6936b83/brick_25972cf5ed7ea81c947c62443ccb308c/brick
Options Reconfigured:
transport.address-family: inet
nfs.disable: on
performance.client-io-threads: off
cluster.brick-multiplex: on
----
<1> According to the output of `oc get pods -o wide` this is the container we are logged on to.

[NOTE]
====
Identify the right brick by looking at the host IP of the GlusterFS pod
you have just logged on to. `oc get pods -o wide` will give you this
information. The host's IP will be noted next to one of the bricks.
====

GlusterFS created this volume as a 3-way replica set across all GlusterFS
pods, and therefore across all your OpenShift App nodes running OCS. Data
written to such a replica volume is replicated 3 times to all *bricks*.
*Bricks* are local storage in GlusterFS nodes, usually backed by a local SAS
*disk or NVMe device. Each node exposes its local storage via the GlusterFS
*protocol. The brick itself is simply a directory on a block device formatted
*with XFS. Hence you can look with a simple `ls` command and see how the data
*is actually stored in each brick.

For easy copying and pasting, here's another bash shortcut to extract the
brick directory path of our PostgreSQL volume from the fist GlusterFS pod in
the list:

[source,bash,role="copypaste"]
----
export PGSQL_GLUSTER_BRICK=$(echo -n $(oc rsh $FIRST_GLUSTER_POD gluster vol info $PGSQL_GLUSTER_VOLUME | grep $FIRST_GLUSTER_IP) | cut -d ':' -f 3 | tr -d $'\r' )
echo $PGSQL_GLUSTER_BRICK
----

You can look at the brick directory of the first GlusterFS pod and see how
GlusterFS stores the files from the clients in a brick:

[source,bash,role="copypaste"]
----
oc rsh $FIRST_GLUSTER_POD ls -ahl $PGSQL_GLUSTER_BRICK
----

You will see something like:

----
total 16K
drwxrwsr-x.   5 root       2001   57 Jun  6 14:44 .
drwxr-xr-x.   3 root       root   19 Jun  6 14:44 ..
drw---S---. 263 root       2001 8.0K Jun  6 14:46 .glusterfs
drwxr-sr-x.   3 root       2001   25 Jun  6 14:44 .trashcan
drwx------.  20 1000080000 2001 8.0K Jun  6 14:46 userdata
----

Dig a bit deeper, try looking at the `userdata` folder:

[source,bash,role="copypaste"]
----
oc rsh $FIRST_GLUSTER_POD ls -ahl $PGSQL_GLUSTER_BRICK/userdata
----

You will see the PostgreSQL database folder structure:

----
total 68K
drwx------. 20 1000080000 2001 8.0K Jun  6 14:46 .
drwxrwsr-x.  5 root       2001   57 Jun  6 14:44 ..
-rw-------.  2 1000080000 root    4 Jun  6 14:44 PG_VERSION
drwx------.  6 1000080000 root   54 Jun  6 14:46 base
drwx------.  2 1000080000 root 8.0K Jun  6 14:47 global
drwx------.  2 1000080000 root   18 Jun  6 14:44 pg_clog
drwx------.  2 1000080000 root    6 Jun  6 14:44 pg_commit_ts
drwx------.  2 1000080000 root    6 Jun  6 14:44 pg_dynshmem
-rw-------.  2 1000080000 root 4.6K Jun  6 14:46 pg_hba.conf
-rw-------.  2 1000080000 root 1.6K Jun  6 14:44 pg_ident.conf
drwx------.  2 1000080000 root   32 Jun  6 14:46 pg_log
drwx------.  4 1000080000 root   39 Jun  6 14:44 pg_logical
drwx------.  4 1000080000 root   36 Jun  6 14:44 pg_multixact
drwx------.  2 1000080000 root   18 Jun  6 14:46 pg_notify
drwx------.  2 1000080000 root    6 Jun  6 14:44 pg_replslot
drwx------.  2 1000080000 root    6 Jun  6 14:44 pg_serial
drwx------.  2 1000080000 root    6 Jun  6 14:44 pg_snapshots
drwx------.  2 1000080000 root    6 Jun  6 14:46 pg_stat
drwx------.  2 1000080000 root   84 Jun  6 15:16 pg_stat_tmp
drwx------.  2 1000080000 root   18 Jun  6 14:44 pg_subtrans
drwx------.  2 1000080000 root    6 Jun  6 14:44 pg_tblspc
drwx------.  2 1000080000 root    6 Jun  6 14:44 pg_twophase
drwx------.  3 1000080000 root   60 Jun  6 14:44 pg_xlog
-rw-------.  2 1000080000 root   88 Jun  6 14:44 postgresql.auto.conf
-rw-------.  2 1000080000 root  21K Jun  6 14:46 postgresql.conf
-rw-------.  2 1000080000 root   46 Jun  6 14:46 postmaster.opts
-rw-------.  2 1000080000 root   89 Jun  6 14:46 postmaster.pid
----

You are looking at the PostgreSQL internal data file structure from the
perspective of the GlusterFS server side. It's a normal local filesystem here.

Clients, like the OpenShift nodes and their application pods talk to this set
of replicated brick storage via the GlusterFS protocol. Which abstracts the
3-way replication behind a single FUSE mount point - this is called a
`volume` in GlusterFS. When a pod starts that mounts storage from a `PV`
backed by GlusterFS, OpenShift will mount the GlusterFS volume on the right
app node and then _bind-mount_ this directory to the right pod. This is
happening transparently to the application inside the pod and looks like a
normal local filesystem.

### Providing Scalable, Shared Storage With OCS
Historically very few options, like basic NFS support, existed to provide a
*PersistentVolume* to more than one container at a time. The access mode used
*for
this in OpenShift is `ReadWriteMany`. Traditional block-based storage
solutions are not able to provide *PersistentVolumes* with this access mode.

Also, once provisioned, most storage cannot easily be resized.

With OCS these capabilities are now available to all OpenShift deployments, no
matter where they are deployed. To illustrate the benefit of this, we will
deploy a PHP file uploader application that has multiple front-end instances
sharing a common storage repository.

#### Deploy the File Uploader Application
First log back in as `fancyuser1` using the password `openshift` and create a
new project:

[source,bash,role="copypaste"]
----
oc login -u fancyuser1 -p openshift
oc new-project my-shared-storage
----

Next deploy the example PHP application called `file-uploader`:

[source,bash,role="copypaste"]
----
oc new-app openshift/php:7.1~https://github.com/christianh814/openshift-php-upload-demo --name=file-uploader
----

You will see something like:

----
--> Found image 691930e (5 weeks old) in image stream "openshift/php" under tag "7.1" for "openshift/php:7.1"

    Apache 2.4 with PHP 7.1 
    ----------------------- 
    PHP 7.1 available as container is a base platform for building and running various PHP 7.1 applications and frameworks. PHP is an HTML-embedded scripting language. PHP attempts to make it easy for developers to write dynamically generated web pages. PHP also offers built-in database integration for several commercial and non-commercial database management systems, so writing a database-enabled webpage with PHP is fairly simple. The most common use of PHP coding is probably as a replacement for CGI scripts.

    Tags: builder, php, php71, rh-php71

    * A source build using source code from https://github.com/christianh814/openshift-php-upload-demo will be created
      * The resulting image will be pushed to image stream tag "file-uploader:latest"
      * Use 'start-build' to trigger a new build
    * This image will be deployed in deployment config "file-uploader"
    * Ports 8080/tcp, 8443/tcp will be load balanced by service "file-uploader"
      * Other containers can access this service through the hostname "file-uploader"

--> Creating resources ...
    imagestream.image.openshift.io "file-uploader" created
    buildconfig.build.openshift.io "file-uploader" created
    deploymentconfig.apps.openshift.io "file-uploader" created
    service "file-uploader" created
--> Success
    Build scheduled, use 'oc logs -f bc/file-uploader' to track its progress.
    Application is not exposed. You can expose services to the outside world by executing one or more of the commands below:
     'oc expose svc/file-uploader' 
    Run 'oc status' to view your app.
----

Watch and wait for the application to be deployed:

[source,bash,role="copypaste"]
----
oc logs -f bc/file-uploader
----

You will see something like:

----
Cloning "https://github.com/christianh814/openshift-php-upload-demo" ...
	Commit:	7508da63d78b4abc8d03eac480ae930beec5d29d (Update index.html)
	Author:	Christian Hernandez <christianh814@users.noreply.github.com>
	Date:	Thu Mar 23 09:59:38 2017 -0700
---> Installing application source...
Pushing image 172.30.120.134:5000/my-shared-storage/file-uploader:latest ...
Pushed 0/5 layers, 2% complete
Pushed 1/5 layers, 20% complete
Pushed 2/5 layers, 40% complete
Push successful
----

The command prompt returns out of the tail mode once you see _Push successful_.

[NOTE]
====
This use of the `new-app` command directly asked for application code to be
built and did not involve a template. That's why it only created a *single
Pod* deployment with a *Service* and no *Route*.
====

Let's make our application production ready by exposing it via a `Route` and
scale to 3 instances for high availability:

[source,bash,role="copypaste"]
----
oc expose svc/file-uploader
oc scale --replicas=3 dc/file-uploader
----

Now, check the *Route* that has been created:

[source,bash,role="copypaste"]
----
oc get route
----

You will see something like:

----
NAME                     HOST/PORT                                                      PATH      SERVICES                 PORT       TERMINATION   WILDCARD
file-uploader            file-uploader-my-shared-storage.{{ OCP_ROUTING_SUFFIX}}                      file-uploader            8080-tcp                 None
...
----

Point your browser to the web application using the URL advertised by the route
(http://file-uploader-my-shared-storage.{{ OCP_ROUTING_SUFFIX}})

The web app simply lists all previously uploaded files and offers the ability
to upload new ones as well as download the existing data. Right now there is
nothing.

Select an arbitrary file from your local machine and upload it to the app.

.A simple PHP-based file upload tool
image::uploader_screen_upload.png[]

Once done click *_List uploaded files_* to see the list of all currently
uploaded files.

Do you see it? Don't worry if you don't.

Change back to the command line and look at the running pods.

[source,bash,role="copypaste"]
----
oc get pods -l app=file-uploader
----

You will see 3 pods running:

----
NAME                    READY     STATUS    RESTARTS   AGE
file-uploader-1-5hhqb   1/1       Running   0          6m
file-uploader-1-trkxr   1/1       Running   0          6m
file-uploader-1-vqszb   1/1       Running   0          7m
----

Now let's look back at where this file got stored inside the pods. Again use
the `oc rsh` utility via a scriptlet to execute an `ls` command on the
`upload` directory that the PHP code uses to store the files:

[source,bash,role="copypaste"]
----
for pod in $(oc get pod -l app=file-uploader --no-headers | awk '{print $1}'); do echo $pod; oc rsh $pod ls -hl uploaded; done
----


You will see that only one of the pods has the uploaded file
----
file-uploader-1-5hhqb
total 0
file-uploader-1-trkxr
total 352K
-rw-r--r--. 1 1000380000 root 352K Oct 29 16:00 firefly-episode-list.txt
file-uploader-1-vqszb
total 0
----

Why is that? These pods currently do not use any persistent storage. They
store the file locally in the container root file system. That means the
application cannot effectively be scaled since the pods do not share data and
every client would see different uploaded files. To verify this, try
accessing the URL with a second _Icognito_ browser session.

[CAUTION]
====
Never attempt to store persistent data in a *Pod* that has no persistent
volume associated with it. *Pods* and their containers are ephemeral by
definition, and any stored data will be lost as soon as the *Pod* terminates
for whatever reason.
====

The app is of course not useful like this. We can fix this by providing shared
storage to this app.

You can create a *PersistentVolumeClaim* and attach it into an application with
the `oc set volume` command. Execute the following

[source,bash,role="copypaste"]
----
oc set volume dc/file-uploader --add --name=my-shared-storage \
-t pvc --claim-mode=ReadWriteMany --claim-size=1Gi \
--claim-name=my-shared-storage --mount-path=/opt/app-root/src/uploaded
----

Like with the `mapit` application in "_Application Management Basics_"
chapter, this command will:

* create a *PersistentVolumeClaim*
* update the *DeploymentConfig* to include a `volume` definition
* update the *DeploymentConfig* to attach a `volumemount` into the specified
  `mount-path`
* cause a new deployment of the application *Pods*

For more information on what `oc set volume` is capable of, look at its help output
with `oc set volume -h`. Now, let's look at the result of adding the volume:

[source,bash,role="copypaste"]
----
oc get pvc
----

You will see something like:

----
NAME                STATUS    VOLUME                                     CAPACITY   ACCESSMODES   AGE
my-shared-storage   Bound     pvc-62aa4dfe-4ad2-11e7-b56f-2cc2602a6dc8   1Gi        RWX           22s
...
----

Notice the `ACCESSMODE` being set to *RWX* (short for `ReadWriteMany`,
equivalent to "shared storage"). Without this `ACCESSMODE`, OpenShift will
not attempt to attach multiple *Pods* to the same *PersistentVolume*
reliably. If you attempt to scale up deployments that are using
`ReadWriteOnce` storage, they will actually all become co-located on the same
node.

The app has now re-deployed (in a rolling fashion) with the new settings -
all pods will mount the volume identified by the PVC under
`/opt/app-root/src/upload`.

Check you have a new set of pods:

[source,bash,role="copypaste"]
----
oc get pods -l app=file-uploader
----

You will see something like:

----
NAME                    READY     STATUS    RESTARTS   AGE
file-uploader-2-4h7bx   1/1       Running   0          2m
file-uploader-2-gqbsn   1/1       Running   0          2m
file-uploader-2-pkmpj   1/1       Running   0          2m
----

Try it out in your file uploader web application using your browser. Upload
new files and see that they are visible from within all application pods.

[CAUTION]
====
Where is my previously uploaded file?

Since the pod redeployed the file has been lost with the previous container's
root filesystem going away as part of the configuration update. One more
reason to provide persistent storage!
====

Once done, return to the command line and look at the contents of pods:

[source,bash,role="copypaste"]
----
for pod in $(oc get pod -l app=file-uploader --no-headers | awk '{print $1}'); do echo $pod; oc rsh $pod ls -hl uploaded; done
----


You will see that now all of the pods have the uploaded file:
----
file-uploader-2-4h7bx
total 352K
-rw-r--r--. 1 1000380000 2002 352K Oct 29 16:10 firefly-episode-list.txt
file-uploader-2-gqbsn
total 352K
-rw-r--r--. 1 1000380000 2002 352K Oct 29 16:10 firefly-episode-list.txt
file-uploader-2-pkmpj
total 352K
-rw-r--r--. 1 1000380000 2002 352K Oct 29 16:10 firefly-episode-list.txt
----

That's it. You have successfully provided shared storage to pods throughout the
entire system, therefore avoiding the need for data to be replicated at the
application level to each pod.

With OCS this is available wherever OpenShift is deployed without external
dependencies like NFS.

### Increasing volume capacity

However, what happens when the volume is full?

Let's try it. Run the following command to fill up the currently 1GiB of free
space in the persistent volume. Since it's shared, you can use any the 3
file-uploader pods:

[source,bash,role="copypaste"]
----
oc rsh $(oc get pod -l app=file-uploader --no-headers | head -n1 | awk '{print $1}') dd if=/dev/zero of=uploaded/bigfile bs=100M count=1000
----

The result after some time is:
----
dd: error writing 'uploaded/bigfile': No space left on device
dd: closing output file 'uploaded/bigfile': No space left on device
command terminated with exit code 1
----

Oops. The file system seems to have a problem. Let's check it:

[source,bash,role="copypaste"]
----
oc rsh $(oc get pod -l app=file-uploader --no-headers | head -n1 | awk '{print $1}') df -h /opt/app-root/src/uploaded
----

Clearly the file system is full:

----
Filesystem                                      Size  Used Avail Use% Mounted on
10.0.1.36:vol_6320cd6974d8573f49f85a5d7255a7f2 1019M 1019M     0 100% /opt/app-root/src/uploaded
----

If you were to try uploading another file via the web application it would fail with something along the lines:

----
[...]
failed to open stream: No space left on device in /opt/app-root/src/upload.php on line 26
[...]
----

Fortunately that is easy to fix for the user or owner of the app, even without administrator intervention.

[WARNING]
====
If you are unfamiliar with the `vi` editor, please run the following command before continuing:

    export EDITOR=nano
====

Use the `oc edit` command to edit the `PersistentVolumeClaim` that we used to
generate the `PersistentVolume`:

[source,bash,role="copypaste"]
----
oc edit pvc my-shared-storage
----

You end up in a `vi` session editing the `PVC` object properties in YAML. Go
to line that says `storage: 1Gi` below spec -> resources -> requests and
increase to `5Gi` like shown below:

[source,yaml]
----
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  annotations:
    pv.kubernetes.io/bind-completed: "yes"
    pv.kubernetes.io/bound-by-controller: "yes"
    volume.beta.kubernetes.io/storage-provisioner: kubernetes.io/glusterfs
  creationTimestamp: 2018-04-18T10:17:24Z
  name: my-shared-storage
  namespace: my-shared-storage
  resourceVersion: "41960"
  selfLink: /api/v1/namespaces/my-shared-storage/persistentvolumeclaims/my-shared-storage
  uid: b0544244-42f1-11e8-8f68-02f9630bd644
spec:
  accessModes:
  - ReadWriteMany
  resources:
    requests:
      storage: 5Gi <1>
  storageClassName: glusterfs-storage
  volumeName: pvc-b0544244-42f1-11e8-8f68-02f9630bd644
status:
  accessModes:
  - ReadWriteMany
  capacity:
    storage: 1Gi
  phase: Bound
----
<1> Set this to *5Gi*

Exit out of `vi` mode with the `:wq` command.

[TIP]
====
Upon writing the file the `oc edit` command will update the
`PersistentVolumeClaim` definition in OpenShift. This way of ad-hoc editing
works with many objects in OpenShift.
====

Give it a couple of seconds and then check the filesystem again:

[source,bash,role="copypaste copypaste-warning"]
----
oc rsh $(oc get pod -l app=file-uploader --no-headers | head -n1 | awk '{print $1}') df -h /opt/app-root/src/uploaded
----

The situation should look much better now:

----
Filesystem                                      Size  Used Avail Use% Mounted on
10.0.1.36:vol_6320cd6974d8573f49f85a5d7255a7f2  5.0G  1.1G  4.0G  21% /opt/app-root/src/uploaded
----

### Providing block storage with OCS

OpenShift Container Storage also contains a block storage persona. At the
very end of every *Pod* accessing a `PersistentVolume` is a filesystem
directory bind-mounted to the container's filesystem namespace. In the case
of GlusterFS it's the GlusterFS filesystem, a POSIX compatible, replicated
shared network filesystem. As of today, OpenShift doesn't support
provisioning a block device directly into a *Pod*. All block storage
supported by OpenShift eventually gets formatted with a filesystem (like
XFS), and is then bind-mounted into the container's filesystem namespace.

When we speak of block storage in OCS, we are talking about an iSCSI LUN
getting provisioned as part of a `PersistentVolumeClaim` against the
block-based `StorageClass` of OCS. This iSCSI LUN is generated from the LIO
stack running in the OCS pods. It is backed by a sparse file which is hosted
on an internal GlusterFS volume. This subsystem is called `gluster-block`.
See below graphic for a representation:

.gluster-block IO flow in OCS
image::cns_diagram_gluster_block.png[]

Why is this beneficial? Some applications, like OpenShift Logging and Metrics
services facilitate operations which are cheap on a local filesystem like XFS
but expensive on distributed filesystem like GlusterFS.

With `gluster-block` you get the advantage of resilient, scalable storage
without the overhead on filesystem operations like locking and byte-range
locking.

OpenShift Metrics and Logging issue a lot of these operations, and hence
*`gluster-block` is currently the only supported backend in OCS for those
services*.

`gluster-block` was deployed in the previous chapter (_Infrastructure
Management Basics_) and used to supply storage to Cassandra as part of the
Metrics service and to ElasticSearch as part of the Logging service.

If you look on the host running any of those service, you will see that there
are iSCSI sessions open.

For example, pick the host running the ElasticSearch pod:

[source,bash,role="copypaste"]
----
oc get pod -l component=es -n openshift-logging -o wide
----

You will see the IP and the hostname of the host the pod is running on.
In this example the pod is running on {{ NODE5_INTERNAL_FQDN }}.

----
NAME                                      READY     STATUS    RESTARTS   AGE       IP            NODE                                         NOMINATED NODE
logging-es-data-master-uud3jzgn-1-tkxsd   2/2       Running   0          1h        10.131.0.24   {{ INFRA_INTERNAL_FQDN }}   <none>
----

[TIP]
====
Above you see one of the examples where a *Pod* actually contains two
containers. The ElasticSearch pod contains an additional proxy service,
living in its own container but running with the actual ElasticSearch service
on the same host.
====

[NOTE]
====
To SSH to hosts in the environment you need to do so from the `cloud-user`
account. The `root` account does not have the SSH keys and `root` SSH is
disabled in this environment.
====

Sign on to this host (use the host shown in the last command) from the master
using SSH and run the `iscsiadm` utility to display running iSCSI sessions:

[source,bash,role="copypaste copypaste-warning"]
----
ssh {{ INFRA_INTERNAL_FQDN }} sudo iscsiadm -m session
----

Answer "*yes*" to the SSH security prompt. You should see output similar to the below:

----
tcp: [1] 10.0.4.80:3260,1 iqn.2016-12.org.gluster-block:f625464b-42b7-4251-8dce-ae78f1bdb17d (non-flash)
tcp: [2] 10.0.1.105:3260,2 iqn.2016-12.org.gluster-block:f625464b-42b7-4251-8dce-ae78f1bdb17d (non-flash)
tcp: [3] 10.0.3.126:3260,3 iqn.2016-12.org.gluster-block:f625464b-42b7-4251-8dce-ae78f1bdb17d (non-flash)
tcp: [4] 10.0.4.80:3260,1 iqn.2016-12.org.gluster-block:236d8c72-3229-4863-9576-3e59055336ec (non-flash)
tcp: [5] 10.0.1.105:3260,2 iqn.2016-12.org.gluster-block:236d8c72-3229-4863-9576-3e59055336ec (non-flash)
tcp: [6] 10.0.3.126:3260,3 iqn.2016-12.org.gluster-block:236d8c72-3229-4863-9576-3e59055336ec (non-flash)
----

The IPs and LUN IDs are going to be different for you, but essentially you
see 3 iSCSI sessions open to the same LUN (identified by the UUID after
`iqn.2016-12.org.gluster-block`). There are 3 sessions because every OCS pod
of the second OCS cluster for Infrastructure runs the Linux iSCSI target
stack (TCMU) and each session represents an independent IO path to the same
LUN, thus achieving high availability and path-based failover.

Like all block storage supplied to OpenShift, it gets formatted with XFS
which you can see if you look at mounts on the host running ElasticSearch:

[source,bash,role="copypaste copypaste-warning"]
----
ssh {{ INFRA_INTERNAL_FQDN }} mount | grep iscsi
----

You will see something similar to this:

----
/dev/mapper/mpatha on /var/lib/origin/openshift.local.volumes/plugins/kubernetes.io/iscsi/iface-default/10.0.4.80:3260-iqn.2016-12.org.gluster-block:f625464b-42b7-4251-8dce-ae78f1bdb17d-lun-0 type xfs (rw,relatime,seclabel,attr2,inode64,noquota)
/dev/mapper/mpatha on /var/lib/origin/openshift.local.volumes/pods/7c8f4b23-db86-11e8-882a-0e4710a83b18/volumes/kubernetes.io~iscsi/pvc-756ad53d-db86-11e8-882a-0e4710a83b18 type xfs (rw,relatime,seclabel,attr2,inode64,noquota)
/dev/mapper/mpathb on /var/lib/origin/openshift.local.volumes/plugins/kubernetes.io/iscsi/iface-default/10.0.4.80:3260-iqn.2016-12.org.gluster-block:236d8c72-3229-4863-9576-3e59055336ec-lun-0 type xfs (rw,relatime,seclabel,attr2,inode64,noquota)
/dev/mapper/mpathb on /var/lib/origin/openshift.local.volumes/pods/4e4cc348-db87-11e8-882a-0e4710a83b18/volumes/kubernetes.io~iscsi/pvc-20fccede-db87-11e8-882a-0e4710a83b18 type xfs (rw,relatime,seclabel,attr2,inode64,noquota)
----

As you can see the devicemapper mulipath devices are how the iSCSI LUN ended
up (in this case) on {{ INFRA_INTERNAL_FQDN}}.

To serve a block device from OCS, a special external provisioner is used. You
can see its *Pod* in the namespace that the second OCS cluster
was deployed to:

[source,bash,role="copypaste"]
----
oc get pod -n {{ CNS_INFRA_NAMESPACE }} -l glusterfs=block-registry-provisioner-pod
----

You should see something like:

----
NAME                                           READY     STATUS    RESTARTS   AGE
glusterblock-registry-provisioner-dc-1-vsgpg   1/1       Running   0          21m
----

This component contains the additional logic to carve out block devices from
OCS.

You will also find evidence of the different provisioning mechanism if you
look at the `StorageClass`:

[source,bash,role="copypaste"]
----
oc get sc
----

Shows the 3 currently defined `StorageClasses` in the system:

----
NAME                          PROVISIONER                AGE
glusterfs-registry            kubernetes.io/glusterfs    58m
glusterfs-registry-block      gluster.org/glusterblock   58m <1>
glusterfs-storage (default)   kubernetes.io/glusterfs    1h
----
<1> The provisioner does not start with `kubernetes.io` which indicates it's
an external provisioner (shipping as an additional component, not as part of
OpenShift or Kubernetes)

Finally, the block device is reflected as a specific type of volume, a
`blockvolume` in `heketi`.

Run the following command to ask `heketi` about all block volumes currently
present using the `heketi-cli` tool:

----
heketi-cli --server http://heketi-registry-{{CNS_INFRA_NAMESPACE}}.{{OCP_ROUTING_SUFFIX}} --user=admin --secret {{ HEKETI_ADMIN_PW }} blockvolume list
----

There should be two, one for Logging and one for Metrics:

----
Id:a2ceeabc91d453a30e197da764fca8c9    Cluster:f68d7554542bab9d0fdeb683d66d951a    Name:blockvol_a2ceeabc91d453a30e197da764fca8c9
Id:a67906a197ad0c750a90c793452f83c7    Cluster:f68d7554542bab9d0fdeb683d66d951a    Name:blockvol_a67906a197ad0c750a90c793452f83c7
----

Using `heketi-cli` you could also provision new block volumes or even create
new internal GlusterFS volumes to host block volumes. However this is rarely
necessary, since this, at time of writing (2018), is only meant to be in
place for Logging and Metrics and provisioning is handled automatically.

### OCS Operations

#### Options to increase Storage Capacity in OCS

At some point the overall OCS cluster capacity may need to be expanded. There are a couple of ways to increase the storage capacity offered by OCS.

1. add a second, independent OCS cluster with its own management stack (`heketi`) (like you did in the _Infrastructure Management_ module )
2. add a second, independent OCS cluster to the existing management stack (as described in the link:https://access.redhat.com/documentation/en-us/container-native_storage/3.9/html-single/container-native_storage_for_openshift_container_platform/#idm140292314514720[documentation^])
3. add additional nodes to an existing OCS cluster (as described in the link:https://access.redhat.com/documentation/en-us/container-native_storage/3.9/html-single/container-native_storage_for_openshift_container_platform/#idm140292314767904[documentation^])
4. add additional devices to existing nodes

Option 1) is automated using `openshift-ansible`

Option 2) is an option you likely want to take when you have nodes with
different media types (SSD vs. HDD) and you want to offer quality of service.

Option 3) allows you to easily expand the cluster capacity in-place. In this
lab we however have no nodes left to add, so we will illustrate Option 4).

#### Adding Additional Devices to a OCS Cluster

To perform management operations we'll use the `heketi-cli` tool. It manages
several entities that make up OCS, that is: clusters, nodes, volumes and
devices.

For each entity there are several create/add, update, delete commands
available. For initial cluster setup `heketi-cli` also offers batch
processing via a JSON file.

In the following we will manually add devices from `node04`, `node05` and
`node06`, which form the OCS cluster for OpenShift infrastructure.

Like in the _Installation_ module, we first set up some Bash environment
variables to configure our `heketi-cli` client to talk to the second OCS
cluster. This time we take a shortcut by programmatically determining the URL
to heketi and the password by querying the `heketi` pod:

[source,bash,role="copypaste"]
----
export HEKETI_POD=$(oc get pods -l glusterfs=heketi-registry-pod -o jsonpath='{.items[0].metadata.name}' -n {{ CNS_INFRA_NAMESPACE }})
export HEKETI_CLI_SERVER=http://$(oc get route -l glusterfs=heketi-registry-route -o jsonpath='{.items[0].spec.host}' -n {{ CNS_INFRA_NAMESPACE }})
export HEKETI_CLI_USER=admin
export HEKETI_CLI_KEY=$(oc get pod/$HEKETI_POD -o jsonpath='{.spec.containers[0].env[?(@.name=="HEKETI_ADMIN_KEY")].value}' -n {{ CNS_INFRA_NAMESPACE }})
----

We can now query `heketi` about the nodes in this cluster:

[source,bash,role="copypaste"]
----
heketi-cli node list
----

And you will see something like:

----
Id:33e0045354db4be29b18728cbe817605	Cluster:ca777ae0285ef6d8cd7237c862bd591c
Id:d8443e7ee8314c0c9fb4d8274a370bbd	Cluster:ca777ae0285ef6d8cd7237c862bd591c
Id:caaed3927e424b22b1a89d261f7617ad	Cluster:ca777ae0285ef6d8cd7237c862bd591c
----

The UUIDs of the nodes will be different for you. We however need them to
tell `heketi` from which nodes to add a device. To avoid repetitive copying
and pasting here is another Bash short cut to parse above output in a Bash
variable:

Run the following command to store the `heketi`-internal ID of the OCS
cluster (there is only one for this `heketi` instance) in a bash variable:

[source,bash,role="copypaste"]
----
export CNS_INFRA_CLUSTER=$(heketi-cli cluster list --json | jq -r '.clusters[0]')
echo $CNS_INFRA_CLUSTER
----

Then get a list of the nodes of this cluster into a Bash variable:

[source,bash,role="copypaste"]
----
export NODES=$(heketi-cli cluster info $CNS_INFRA_CLUSTER --json | jq -r '.nodes[]')
export NODE_LIST=($NODES)
echo $NODES
----

To illustrate the before and after effect, first inspect the output of:

[source,bash,role="copypaste"]
----
heketi-cli topology info
----

You should see that every node currently has a single device: `{{NODE_BRICK_DEVICE}}`.

These nodes of the second OCS cluster, have an additional, unused storage
device `{{NODE_BRICK_DEVICE2}}`. For each node now go ahead and make `heketi`
aware of this device using the `device add` directive

[source,bash,role="copypaste"]
----
heketi-cli device add --name={{NODE_BRICK_DEVICE2}} --node=${NODE_LIST[0]}
heketi-cli device add --name={{NODE_BRICK_DEVICE2}} --node=${NODE_LIST[1]}
heketi-cli device add --name={{NODE_BRICK_DEVICE2}} --node=${NODE_LIST[2]}
----

Each command should return with the message `Device added successfully`.

Check `heketi-cli topology info` again to verify the presence of the new
devices.

That's it - the devices are now available to `heketi` and will be considered
the next time OCS serves a volume request. Adding devices and nodes are
online operations, meaning they are non-disruptive and can be run in
production without downtime.

### Replacing Failed Disks and Nodes

When a device fails, OCS transparently continues operations with the
remaining replicas. You will need to replace such components to move out of a
degraded state and get to 3 replicas again, either using other devices free
capacity in the same node or in different nodes.

For this exercise, let's assume the device `{{ NODE_BRICK_DEVICE }}` of your
node {{ NODE4_INTERNAL_FQDN }} failed and you need to replace it. You can do
that as long as there is enough spare capacity somewhere else in the cluster,
preferrable but not necessarily in the same failure domain (as specifed in
the topology).

[TIP]
====
OCS is aware of failure domains in your infrastructure. These could be racks
in a data center or availability zones in public cloud environments. The
zones are identified by distinct values in the `zone` parameter of each node.
Nodes with the same value for `zone` are considered part of the same failure
domain. OCS will try to do its best (but not enforce it) to replicate and
rebalance data across 3 different failure domains at all times.
====

The first step is to determine the OCS node's internal UUID in heketi's
database. You can do that manually:

[source,bash,role="copypaste"]
----
heketi-cli topology info | grep -B4 {{NODE4_INTERNAL_FQDN}}
----

...and see something like:

----
	Node Id: 33e0045354db4be29b18728cbe817605
	State: online
	Cluster Id: ca777ae0285ef6d8cd7237c862bd591c
	Zone: 1
	Management Hostname: {{NODE4_INTERNAL_FQDN}}
----

Or you can do it programmatically, for easy copying and pasting, by asking `heketi` and parsing its JSON output using `jq`:

[source,bash,role="copypaste"]
----
NODE_4_ID=$(heketi-cli topology info --json | jq -r ".clusters[] | select(.id==\"$CNS_INFRA_CLUSTER\") | .nodes[] | select(.hostnames.manage[0] == \"{{NODE4_INTERNAL_FQDN}}\") | .id")
echo $NODE_4_ID
----

This should yield, like above `33e0045354db4be29b18728cbe817605`

Second, determine the device's UUID by querying the node (indicated above by
`Node Id`):

Again, you could do this manually by looking at `heketi` information about the node:

[source,bash,role="copypaste"]
----
heketi-cli node info $NODE_4_ID
----

And then you will see:

----
Node Id: 33e0045354db4be29b18728cbe817605
State: online
Cluster Id: 119ea7f96ce132f15a04c28de9978018
Zone: 1
Management Hostname: {{ NODE4_INTERNAL_FQDN }}
Storage Hostname: {{ NODE4_INTERNAL_IP }}
Devices:
Id:0b32d5e57f2047485e42e6288405ad7f   Name:{{ NODE_BRICK_DEVICE2 }}           State:online    Size (GiB):49      Used (GiB):0       Free (GiB):49
Id:4fb2ae473d5ee451906d5489abfc653e   Name:{{ NODE_BRICK_DEVICE }}           State:online    Size (GiB):49      Used (GiB):42      Free (GiB):7
----

Or again, for easy copying and pasting, you can do it the smart way and retrieve the device ID of `{{NODE_BRICK_DEVICE}}` programmatically from the JSON output using `jq`:

[source,bash,role="copypaste"]
----
export FAILED_DEVICE_ID=$(heketi-cli node info $NODE_4_ID  --json | jq -r '.devices[] | select(.name=="{{ NODE_BRICK_DEVICE }}") | .id')
echo $FAILED_DEVICE_ID
----

You should get the UUID of `{{ NODE_BRICK_DEVICE }}` from this command, in
this example `4fb2ae473d5ee451906d5489abfc653e`.

With the UUID we can first mark the device as offline to stop heketi from
further attempts to allocate space from it:

[source,bash,role="copypaste"]
----
heketi-cli device disable $FAILED_DEVICE_ID
----

You will see something like:

----
Device 4fb2ae473d5ee451906d5489abfc653e is now offline
----

The device is now offline but it's still part of replicated volumes. To remove
it and trigger a self-healing operation in the background issue:

[source,bash,role="copypaste"]
----
heketi-cli device remove $FAILED_DEVICE_ID
----

You will see something like:

----
Device 4fb2ae473d5ee451906d5489abfc653e is now removed
----

[NOTE]
====
This command can take a bit long as it will go through the topology and
search for the next available device on the same node, in the same failure
domain or in the rest of the cluster (in that order) and trigger a
*brick-replacement operation*. That is, the data from the failed brick is
re-replicated to another health storage device and the 3-way replicated
storage volume moves out of degraded state.
====

This is an online operation and can absolutely be run in production.

Our failed device is still lurking around in _failed_ state. To finally get
rid of it issue:

[source,bash,role="copypaste"]
----
heketi-cli device delete $FAILED_DEVICE_ID
----

You will see something like:

----
Device 4fb2ae473d5ee451906d5489abfc653e deleted
----

[NOTE]
====
Only devices that are not currently used by other Gluster volumes can be
deleted. If that's not the case, `heketi-cli` will tell you about it. Devices
that are in use always need to have `remove` performed first.
====

You can now check that the device is gone from the topology by running:

[source,bash,role="copypaste"]
----
heketi-cli topology info
----

*Node deletion* is also possible and is basically comprised of:

1. successful execution of the `remove` operation on all devices of the node
2. running `heketi-cli node delete <node_id>` on the node in question
