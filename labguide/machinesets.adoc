## MachineSets, Machines, and Nodes

Kubernetes `Nodes` are where containers are orchestrated and run in `Pods`.
OpenShift 4 is fundamentally different than OpenShift 3 with respect to its
focus on automated operations through the user of `Operators`. With respect
to `Nodes`, there is a set of `Operators` and controllers that are focused on
maintaining the state of the cluster size -- including creating and
destroying `Nodes`!

### MachineSets and Machines
As you saw in the application management exercises, there is a basic
fundamental relationship between a `ReplicaSet`/`ReplicationController` and
the `Pods` it creates. Similarly, there is a relationship between a
`MachineSet` and a `Machine`.

The `MachineSet` defines a desired state for a set of `Machine` objects. When
using IPI installations, then, there is an `Operator` whose job it is to make
sure that there is actually an underlying instance for each `Machine` and,
finally, that every `Machine` becomes a `Node`.

Execute the following:

[source,bash,role="copypaste"]
----
oc get machineset -n openshift-machine-api
----

You will see something like:

----
NAME                                   DESIRED   CURRENT   READY   AVAILABLE   AGE
cluster-f4a3-lpxbs-worker-us-east-2a   1         1         1       1           47h
cluster-f4a3-lpxbs-worker-us-east-2b   1         1         1       1           47h
cluster-f4a3-lpxbs-worker-us-east-2c   1         1         1       1           47h
----

When OpenShift was installed, the installer interrogated the cloud provider
to learn about the available AZs (since this is on AWS). It then ultimately
created a `MachineSet` for each AZ and then scaled those sets, in order,
until it reached the desired number of `Machines`. Since the default
installation has 3 workers, the first 3 AZs got one worker each. The rest got
zero.

[source,bash,role="copypaste"]
----
oc get machine -n openshift-machine-api
----

You will see something like:

----
NAME                                         INSTANCE              STATE     TYPE         REGION      ZONE         AGE
cluster-f4a3-lpxbs-master-0                  i-04280885cafad3130   running   m4.xlarge    us-east-2   us-east-2a   47h
cluster-f4a3-lpxbs-master-1                  i-0def910edcae51d11   running   m4.xlarge    us-east-2   us-east-2b   47h
cluster-f4a3-lpxbs-master-2                  i-0beb5e40214d706fc   running   m4.xlarge    us-east-2   us-east-2c   47h
cluster-f4a3-lpxbs-worker-us-east-2a-b94pr   i-0a922c0fe765caa3c   running   m4.large     us-east-2   us-east-2a   47h
cluster-f4a3-lpxbs-worker-us-east-2b-m8gbx   i-0fb8d960b8a3a3343   running   m4.large     us-east-2   us-east-2b   47h
cluster-f4a3-lpxbs-worker-us-east-2c-5tmg7   i-0151c72cd85f85038   running   m4.large     us-east-2   us-east-2c   47h
----

Each `Machine` has a corresponding `INSTANCE`. Do those IDs look familiar?
They are AWS EC2 instance IDs. You also see `Machines` for the OpenShift
masters. They are not part of a `MachineSet` because they are somewhat
stateful and their management is handled by different operators and through a
different process.

[WARNING]
====
There is currently no protection for the master `Machines`. Do not
accidentally or intentionally delete them, as this will potentially break
your cluster. It is repairable, but it is not fun.
====

Lastly, execute:

[source,bash,role="copypaste"]
----
oc get nodes
----

You will see something like:

----
NAME                           STATUS   ROLES          AGE   VERSION
ip-10-0-129-33.ec2.internal    Ready    master         47h   v1.12.4+509916ce1
ip-10-0-139-97.ec2.internal    Ready    worker         47h   v1.12.4+509916ce1
ip-10-0-144-15.ec2.internal    Ready    master         47h   v1.12.4+509916ce1
ip-10-0-157-196.ec2.internal   Ready    worker         47h   v1.12.4+509916ce1
ip-10-0-164-163.ec2.internal   Ready    master         47h   v1.12.4+509916ce1
ip-10-0-175-100.ec2.internal   Ready    worker         47h   v1.12.4+509916ce1
----

Each `Machine` ends up corresponding to a `Node`. With IPI, there is a
bootstrap process where the machine operator will create an EC2 instance and
then Ignition inside the CoreOS operating system will receive initial
instructions from the operator. This results in the EC2 instance being
configured as an OpenShift node and joining the cluster.

If you spend some time using `oc describe` and the various `Machine` and
`Node` objects, you will figure out which ones correlate with which.

### Cluster Scaling
Because of the magic of `Operators` and the way in which OpenShift uses them
to manage `Machines` and `Nodes`, scaling your cluster in OpenShift 4 is
extremely trivial.

Look at the list of `MachineSets` again:

[source,bash,role="copypaste"]
----
oc get machineset -n openshift-machine-api
----

Within that list, find the `MachineSet` that ends in `-2c`. It should have a
scale of one. Now, let's scale it to have two instances:

[source,bash,role="copypaste copypaste-warning"]
----
oc scale machineset cluster-5fa6-hx2ml-worker-us-east-2c -n openshift-machine-api --replicas=2
----

Take special note because your `MachineSet` name is likely different from the
one in the lab guide. You should see a note that the `MachineSet` was
successfully scaled. Now, look at the list of `Machines`:

[source,bash,role="copypaste"]
----
oc get machines -n openshift-machine-api
----

You probably already have a new entry for a `Machine` with a `STATE` of
`Pending`. After a few moments, it will have a corresponding EC2 instance ID
and will look something like:

----
cluster-f4a3-lpxbs-worker-us-east-2c-h7gdt   i-0b9208ec47f0e206b   running   m4.large     us-east-2   us-east-2c   47s
----

At this point, in the background, the bootstrap process is happening
automatically. After several minutes (up to five or so), take a look at the
output of:

[source,bash,role="copypaste"]
----
oc get nodes
----

You should see your fresh and happy new node as the one with a very young age:

----
ip-10-0-194-62.ec2.internal    Ready    worker         1m   v1.12.4+509916ce1
----

Scale the `MachineSet` from one back down to zero before continuing.